{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/pt113/lib/python3.9/site-packages/torchvision/io/image.py:11: UserWarning: Failed to load image Python extension: \n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import timm\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "from timm.data.loader import create_loader\n",
    "from timm.data.dataset import ImageDataset\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "from ViT.tooth_crop_dataset import ToothCropClassDataset\n",
    "from utils.preprocess import rect_include_another, rotate_bounding_boxes, xyxy_reformat, xyxy2xywh\n",
    "from utils.yolo import get_teeth_ROI\n",
    "from utils.edge import tooth_isolation, bounding_teeth_on_origin, get_all_teeth\n",
    "\n",
    "load_dotenv()\n",
    "matplotlib.use('module://matplotlib_inline.backend_inline')\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model & env variable loaded"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '.\\\\YOLO/hubconf.py'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-2-1fdd6842412d>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mtooth_detect_model\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mhub\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mload\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34mr'.\\YOLO'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'custom'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpath\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34mr'.\\YOLO\\weights\\8-bound.pt'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msource\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'local'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0manomaly_detect_model\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mhub\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mload\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34mr'.\\YOLO'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'custom'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpath\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34mr'.\\YOLO\\weights\\anomaly.pt'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msource\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'local'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0;31m# data_dir = '.' / Path(os.getenv('DATASET_DIR'))\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0mdata_dir\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mPath\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'..'\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m/\u001B[0m \u001B[0;34m'Datasets'\u001B[0m \u001B[0;34m/\u001B[0m \u001B[0;34m'phase-2'\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/miniconda3/envs/pt113/lib/python3.9/site-packages/torch/hub.py\u001B[0m in \u001B[0;36mload\u001B[0;34m(repo_or_dir, model, source, force_reload, verbose, skip_validation, *args, **kwargs)\u001B[0m\n\u001B[1;32m    397\u001B[0m         \u001B[0mrepo_or_dir\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_get_cache_or_reload\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mrepo_or_dir\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mforce_reload\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mverbose\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mskip_validation\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    398\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 399\u001B[0;31m     \u001B[0mmodel\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_load_local\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mrepo_or_dir\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    400\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    401\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/miniconda3/envs/pt113/lib/python3.9/site-packages/torch/hub.py\u001B[0m in \u001B[0;36m_load_local\u001B[0;34m(hubconf_dir, model, *args, **kwargs)\u001B[0m\n\u001B[1;32m    423\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    424\u001B[0m     \u001B[0mhubconf_path\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mos\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpath\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mjoin\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mhubconf_dir\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mMODULE_HUBCONF\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 425\u001B[0;31m     \u001B[0mhub_module\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mimport_module\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mMODULE_HUBCONF\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mhubconf_path\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    426\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    427\u001B[0m     \u001B[0mentry\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_load_entry_from_hubconf\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mhub_module\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/miniconda3/envs/pt113/lib/python3.9/site-packages/torch/hub.py\u001B[0m in \u001B[0;36mimport_module\u001B[0;34m(name, path)\u001B[0m\n\u001B[1;32m     74\u001B[0m     \u001B[0mmodule\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mimportlib\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mutil\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmodule_from_spec\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mspec\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     75\u001B[0m     \u001B[0;32massert\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mspec\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mloader\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mLoader\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 76\u001B[0;31m     \u001B[0mspec\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mloader\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mexec_module\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmodule\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     77\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0mmodule\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     78\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/miniconda3/envs/pt113/lib/python3.9/importlib/_bootstrap_external.py\u001B[0m in \u001B[0;36mexec_module\u001B[0;34m(self, module)\u001B[0m\n",
      "\u001B[0;32m/opt/miniconda3/envs/pt113/lib/python3.9/importlib/_bootstrap_external.py\u001B[0m in \u001B[0;36mget_code\u001B[0;34m(self, fullname)\u001B[0m\n",
      "\u001B[0;32m/opt/miniconda3/envs/pt113/lib/python3.9/importlib/_bootstrap_external.py\u001B[0m in \u001B[0;36mget_data\u001B[0;34m(self, path)\u001B[0m\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: '.\\\\YOLO/hubconf.py'"
     ]
    }
   ],
   "source": [
    "tooth_detect_model = torch.hub.load(r'.\\YOLO', 'custom', path=r'.\\YOLO\\weights\\8-bound.pt', source='local')\n",
    "anomaly_detect_model = torch.hub.load(r'.\\YOLO', 'custom', path=r'.\\YOLO\\weights\\anomaly.pt', source='local')\n",
    "\n",
    "# data_dir = '.' / Path(os.getenv('DATASET_DIR'))\n",
    "data_dir = Path('..') / 'Datasets' / 'phase-2'\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "image_names = list(data_dir.glob('00008145.jpg'))\n",
    "\n",
    "image_names = image_names[:20]\n",
    "image_name = image_names[0]\n",
    "filename = image_name.stem\n",
    "\n",
    "im = cv2.imread(image_name)\n",
    "# Only plt imshow need inverse process\n",
    "plt.imshow(1 - im)\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "results = tooth_detect_model(image_names)\n",
    "rendered_results = results.render()\n",
    "\n",
    "plt.imshow(1 - rendered_results[0])\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "anomaly_results = anomaly_detect_model(image_names)\n",
    "rendered_anomaly_results = anomaly_results.render()\n",
    "\n",
    "plt.imshow(1 - rendered_anomaly_results[0])\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "results = tooth_detect_model(image_names)\n",
    "teeth_region = get_all_teeth(results)\n",
    "teeth_roi = get_teeth_ROI(results)\n",
    "\n",
    "teeth_region\n",
    "teeth_roi\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Save tooth crop image"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "temp_dir = '.' / Path(os.getenv('TEMP_DIR')) / 'crop_tooth_image'\n",
    "\n",
    "missing_tooth = []\n",
    "for file in temp_dir.glob('*.jpg'):\n",
    "    os.remove(file)\n",
    "\n",
    "for filename, region in teeth_region.items():\n",
    "    for region_name, tooth_region in region.items():\n",
    "        for tooth_number, data in tooth_region['crop_regions'].items():\n",
    "            crop_image = data['crop_image']\n",
    "            is_missing = data['is_missing']\n",
    "\n",
    "            if is_missing:\n",
    "                missing_tooth.append((filename, tooth_number))\n",
    "                continue\n",
    "            save_filepath = temp_dir / f'{filename} {region_name} {tooth_number}.jpg'\n",
    "\n",
    "            temp_im = Image.fromarray(crop_image)\n",
    "            temp_im.save(save_filepath)\n",
    "\n",
    "# print(save_filepath)\n",
    "missing_tooth\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model loading"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_dir = '.' / Path(os.getenv('ViT_MODEL_DIR'))\n",
    "model_path = model_dir / 'classifier-6.pt'\n",
    "\n",
    "vit_model = timm.create_model('swin_base_patch4_window7_224_in22k', num_classes=6)\n",
    "vit_model.load_state_dict(torch.load(model_path))\n",
    "vit_model\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "batch_size = 16\n",
    "num_workers = 0\n",
    "\n",
    "# Preprocess\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    # (lambda image: padding_to_size(image, 224)),\n",
    "    transforms.Resize(size=(224, 224)),\n",
    "    transforms.Normalize(mean=0.5, std=0.5),\n",
    "])\n",
    "target_transform = transforms.Compose([\n",
    "    (lambda y: torch.Tensor(y)),\n",
    "])\n",
    "dataset = ImageDataset(temp_dir, transform=transform)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    dataloader = create_loader(dataset, (3, 224, 224), 4)\n",
    "else:\n",
    "    dataloader = create_loader(dataset, (3, 224, 224), 4, use_prefetcher=False)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "size = len(dataloader.dataset)\n",
    "\n",
    "vit_model.to(device)\n",
    "vit_model.eval()\n",
    "\n",
    "threshold = torch.Tensor([0.5, 0.85, 0.5, 0.5, 0.5, 0.5]).to(device)\n",
    "pred_encodes = []\n",
    "# target_labels = ['caries', 'endo', 'post', 'crown']\n",
    "# target_labels = ['R.R', 'caries', 'crown', 'endo', 'filling', 'post']\n",
    "target_labels = ['caries', 'crown', 'endo', 'filling', 'post']\n",
    "with torch.no_grad():\n",
    "    for batch, (X, _) in enumerate(dataloader):\n",
    "        X = X.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = vit_model(X)\n",
    "        pred = torch.sigmoid(pred)\n",
    "        pred_encode = pred > threshold\n",
    "        pred_encodes.append(pred_encode.cpu().numpy())\n",
    "\n",
    "pred_encodes = np.vstack(pred_encodes)\n",
    "pred_encodes = pred_encodes[:, 1:]\n",
    "detected_list = [()] * len(pred_encodes)\n",
    "for i, pred_encode in enumerate(pred_encodes):\n",
    "    detected_list[i] = tuple((target_labels[j] for j, checker in enumerate(pred_encode) if checker))\n",
    "\n",
    "detected_list\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tooth_anomaly_dict = {anomaly_results.files[i][:-4]: {} for i in range(len(anomaly_results))}\n",
    "\n",
    "for i, detected in enumerate(detected_list):\n",
    "    current_filename, region_name, tooth_number = dataset.filename(i).split()\n",
    "    tooth_number = int(tooth_number[:2])\n",
    "\n",
    "    if tooth_number < 50:\n",
    "        tooth_anomaly_dict[current_filename][tooth_number] = set(detected)\n",
    "\n",
    "print(tooth_anomaly_dict)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# YOLO anomaly detect\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "iou_threshold = 0.3\n",
    "region_wisdom_tooth_dict = {\n",
    "    'upper-left': 18,\n",
    "    'upper-right': 28,\n",
    "    'lower-left': 48,\n",
    "    'lower-right': 38,\n",
    "}\n",
    "\n",
    "for i in range(len(anomaly_results)):\n",
    "    current_filename = anomaly_results.files[i][:-4]\n",
    "    anomaly_bounds = anomaly_results.xyxy[i]\n",
    "    for j in range(len(anomaly_bounds)):\n",
    "        *xyxy, _, cls = anomaly_bounds[j]\n",
    "        xyxy = list(map(lambda t: t.cpu(), xyxy))\n",
    "\n",
    "        cls = int(cls.item())\n",
    "        name = anomaly_results.names[cls]\n",
    "        # if name in target_labels:\n",
    "        #     continue\n",
    "\n",
    "        # for x8 tooth\n",
    "        if name in ['embedded', 'impacted']:\n",
    "            min_distance = np.inf\n",
    "            near_region = ''\n",
    "            for region_data in teeth_roi['images'][current_filename]:\n",
    "                region_xyxy = region_data['xyxy']\n",
    "                region_xywh = xyxy2xywh(np.vstack([region_xyxy]))[0]\n",
    "\n",
    "                xywh = xyxy2xywh(np.vstack([xyxy]))[0]\n",
    "\n",
    "                distance = np.linalg.norm(xywh[:2] - region_xywh[:2])\n",
    "                if distance < min_distance:\n",
    "                    min_distance = distance\n",
    "                    near_region = f'{region_data[\"flag\"]}-{region_data[\"tooth_position\"]}'\n",
    "            if near_region in region_wisdom_tooth_dict:\n",
    "                tooth_number = region_wisdom_tooth_dict[near_region]\n",
    "                if tooth_number not in tooth_anomaly_dict[current_filename].keys():\n",
    "                    tooth_anomaly_dict[current_filename][tooth_number] = {name}\n",
    "                else:\n",
    "                    tooth_anomaly_dict[current_filename][tooth_number].add(name)\n",
    "            continue\n",
    "\n",
    "        # for normal tooth\n",
    "        located_regions = {}\n",
    "        for region_data in teeth_roi['images'][current_filename]:\n",
    "            region_xyxy = region_data['xyxy']\n",
    "            if rect_include_another(region_xyxy, xyxy) > iou_threshold:\n",
    "                located_regions[f'{region_data[\"flag\"]}-{region_data[\"tooth_position\"]}'] = region_data\n",
    "\n",
    "        for located_region, region_data in located_regions.items():\n",
    "            region_tooth_data = teeth_region[current_filename][located_region]\n",
    "            tooth_angle = np.radians(region_tooth_data['angle'])\n",
    "\n",
    "            offset = region_data['offset']\n",
    "            region_image_shape = np.array(np.array(region_data['image'].shape)[[1, 0]])\n",
    "\n",
    "            rotated_xyxy = [xyxy]\n",
    "            rotated_xyxy = np.array(rotated_xyxy) - np.tile(offset, 2)\n",
    "            rotated_xyxy = rotate_bounding_boxes(tooth_angle, region_image_shape, rotated_xyxy)\n",
    "            rotated_xyxy = rotated_xyxy[0].astype(int)\n",
    "\n",
    "            tooth_number_candidate = []\n",
    "            for tooth_number, tooth_data in region_tooth_data['crop_regions'].items():\n",
    "                if tooth_number > 50:\n",
    "                    continue\n",
    "\n",
    "                tooth_xyxy = tooth_data['xyxy']\n",
    "                # print(name)\n",
    "                # print(rect_include_another(tooth_xyxy, rotated_xyxy))\n",
    "                tooth_iou = rect_include_another(tooth_xyxy, rotated_xyxy)\n",
    "\n",
    "                if tooth_iou > 0:\n",
    "                    tooth_number_candidate.append((tooth_number, tooth_iou))\n",
    "\n",
    "                # if rect_include_another(tooth_xyxy, rotated_xyxy) > iou_threshold:\n",
    "                #     tooth_anomaly_dict[current_filename][tooth_number].add(name)\n",
    "            if tooth_number_candidate:\n",
    "                tooth_number, tooth_iou = max(tooth_number_candidate, key=lambda t: t[1])\n",
    "                tooth_anomaly_dict[current_filename][tooth_number].add(name)\n",
    "\n",
    "\n",
    "for pair in missing_tooth:\n",
    "    filename, tooth_number = pair\n",
    "    tooth_anomaly_dict[filename][tooth_number] = {'missing'}\n",
    "\n",
    "print(tooth_anomaly_dict)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#\n",
    "# with open('output.json', 'r') as f:\n",
    "#     output = json.load(f)\n",
    "# output[image_name.stem]\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
