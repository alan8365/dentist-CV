{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/pt113/lib/python3.9/site-packages/torchvision/io/image.py:11: UserWarning: Failed to load image Python extension: \n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import timm\n",
    "import shutil\n",
    "import torch\n",
    "from dotenv import load_dotenv\n",
    "from timm.data import ImageDataset, create_loader\n",
    "from torchvision import transforms\n",
    "from ultralytics import YOLO\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "temp_dir = Path(os.getenv('TEMP_DIR')) / 'crop_tooth_image'\n",
    "model_dir = Path(os.getenv('ViT_MODEL_DIR'))\n",
    "data_dir = Path(os.getenv('DATASET_DIR')) / 'phase-2'\n",
    "yolo_model_dir = Path(os.getenv('YOLO_MODEL_DIR'))\n",
    "yolo_dir = yolo_model_dir / '..'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "[PosixPath('/Users/lucyxu/PycharmProjects/datasets/phase-2/00006145.jpg'),\n PosixPath('/Users/lucyxu/PycharmProjects/datasets/phase-2/00008026.jpg'),\n PosixPath('/Users/lucyxu/PycharmProjects/datasets/phase-2/00008075.jpg')]"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src = ['00006145.jpg', '00008026.jpg', '00008075.jpg']\n",
    "src = [data_dir / i for i in src]\n",
    "\n",
    "src\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 320x640 1 11, 1 12, 2 13s, 2 14s, 2 15s, 2 16s, 1 17, 1 21, 1 22, 1 23, 1 26, 1 28, 1 31, 1 32, 1 33, 1 34, 1 35, 1 37, 1 41, 1 42, 1 43, 2 44s, 2 45s, 1 47, 2 48s, 1: 320x640 1 11, 1 12, 1 13, 1 14, 1 15, 1 16, 1 18, 1 21, 1 22, 1 23, 1 24, 1 25, 1 26, 1 27, 1 28, 1 31, 1 32, 1 33, 1 34, 1 35, 1 36, 1 37, 1 38, 1 41, 1 42, 1 43, 1 44, 1 45, 1 46, 1 47, 1 48, 2: 320x640 1 11, 1 12, 1 13, 1 14, 2 15s, 1 16, 1 17, 1 21, 1 22, 1 23, 1 24, 1 25, 1 26, 1 27, 1 28, 1 31, 1 32, 1 33, 1 34, 1 35, 1 36, 1 37, 1 41, 1 42, 1 43, 1 44, 1 45, 1 46, 2 47s, 140.1ms\n",
      "Speed: 2.3ms preprocess, 46.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    }
   ],
   "source": [
    "model = YOLO(yolo_model_dir / 'enumerate.pt')\n",
    "\n",
    "results = model(src)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "for file in temp_dir.glob('*.jpg'):\n",
    "    os.remove(file)\n",
    "\n",
    "for result in results:\n",
    "    filename = Path(result.path).stem\n",
    "    result.save_crop(temp_dir, filename)\n",
    "\n",
    "all_dir = list(temp_dir.glob('*'))\n",
    "\n",
    "for im_path in list(temp_dir.glob('**/*.jpg')):\n",
    "    filename = im_path.stem\n",
    "    tooth_number = str(im_path).split('/')[-2]\n",
    "\n",
    "    src_path = im_path\n",
    "    dst_path = temp_dir / f'{filename}-{tooth_number}.jpg'\n",
    "\n",
    "    shutil.move(src_path, dst_path)\n",
    "\n",
    "for my_dir in all_dir:\n",
    "    if os.path.isdir(my_dir):\n",
    "        os.rmdir(my_dir)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "94"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(temp_dir.glob(\"*.jpg\")))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/pt113/lib/python3.9/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "# Vit model loading\n",
    "model_path = model_dir / 'yolov8-base.pt'\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "vit_model = timm.create_model('swin_base_patch4_window7_224_in22k', num_classes=6)\n",
    "vit_model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "vit_model.to(device)\n",
    "vit_model.eval()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# Preprocess\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    # (lambda image: padding_to_size(image, 224)),\n",
    "    transforms.Resize(size=(224, 224)),\n",
    "    transforms.Normalize(mean=0.5, std=0.5),\n",
    "])\n",
    "target_transform = transforms.Compose([\n",
    "    (lambda y: torch.Tensor(y)),\n",
    "])\n",
    "dataset = ImageDataset(temp_dir, transform=transform)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    dataloader = create_loader(dataset, (3, 224, 224), 4)\n",
    "else:\n",
    "    dataloader = create_loader(dataset, (3, 224, 224), 4, use_prefetcher=False)\n",
    "\n",
    "size = len(dataloader.dataset)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "threshold = torch.Tensor([0.5, 0.85, 0.5, 0.5, 0.5, 0.5]).to(device)\n",
    "pred_encodes = []\n",
    "# target_labels = ['caries', 'endo', 'post', 'crown']\n",
    "target_labels = ['R.R', 'caries', 'crown', 'endo', 'filling', 'post']\n",
    "# target_labels = ['caries', 'crown', 'endo', 'filling', 'post']\n",
    "with torch.no_grad():\n",
    "    for batch, (X, _) in enumerate(dataloader):\n",
    "        X = X.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = vit_model(X)\n",
    "        pred_encode = pred > threshold\n",
    "        pred_encodes.append(pred_encode.cpu().numpy())\n",
    "\n",
    "pred_encodes = np.vstack(pred_encodes)\n",
    "pred_encodes = pred_encodes[:, 1:]\n",
    "detected_list = [()] * len(pred_encodes)\n",
    "for im_path, pred_encode in enumerate(pred_encodes):\n",
    "    detected_list[im_path] = tuple((target_labels[j] for j, checker in enumerate(pred_encode) if checker))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[False, False, False, False, False],\n       [ True, False, False, False, False],\n       [ True, False, False, False, False],\n       [ True, False, False, False, False],\n       [ True, False, False, False, False],\n       [False, False, False, False, False],\n       [False, False, False,  True, False],\n       [False, False,  True, False, False],\n       [False, False, False, False, False],\n       [False, False, False, False, False],\n       [False, False, False, False, False],\n       [False, False, False, False, False],\n       [ True, False, False, False, False],\n       [ True, False, False, False, False],\n       [ True, False, False, False, False],\n       [False, False,  True, False, False],\n       [ True, False, False, False, False],\n       [False, False, False,  True, False],\n       [False, False, False, False, False],\n       [False, False, False, False, False],\n       [ True, False, False, False, False],\n       [False, False, False, False, False],\n       [False, False, False, False, False],\n       [False, False, False,  True, False],\n       [False, False,  True, False, False],\n       [False, False,  True, False,  True],\n       [False, False, False, False, False],\n       [False, False, False, False, False],\n       [False, False, False, False, False],\n       [False, False, False, False, False],\n       [False, False,  True, False, False],\n       [False, False, False, False, False],\n       [False, False,  True, False,  True],\n       [False, False, False,  True, False],\n       [ True, False, False, False, False],\n       [False, False, False, False, False],\n       [False, False, False,  True, False],\n       [False,  True, False, False, False],\n       [False, False, False, False, False],\n       [False, False, False, False, False],\n       [False, False, False, False, False],\n       [False, False, False, False, False],\n       [False, False, False, False, False],\n       [False, False,  True, False, False],\n       [False, False, False,  True, False],\n       [False, False, False, False, False],\n       [False, False, False, False, False],\n       [False, False, False,  True, False],\n       [False, False, False, False, False],\n       [ True, False, False, False, False],\n       [False, False, False, False, False],\n       [False, False, False, False, False],\n       [ True, False, False, False, False],\n       [False, False, False,  True, False],\n       [False, False, False,  True, False],\n       [False, False, False, False, False],\n       [False, False, False, False, False],\n       [False, False, False, False, False],\n       [False, False, False,  True, False],\n       [False, False, False, False, False],\n       [False, False, False, False, False],\n       [False, False, False,  True, False],\n       [False,  True, False, False, False],\n       [False, False, False, False, False],\n       [False, False, False,  True, False],\n       [False, False, False,  True, False],\n       [False, False, False, False, False],\n       [False, False, False, False, False],\n       [False, False, False, False, False],\n       [False, False, False, False, False],\n       [False, False, False, False, False],\n       [ True, False, False, False, False],\n       [ True, False, False, False, False],\n       [False, False, False, False, False],\n       [False, False,  True, False, False],\n       [False, False, False,  True, False],\n       [False, False,  True, False, False],\n       [False, False, False, False, False],\n       [False, False, False, False, False],\n       [False, False, False, False, False],\n       [ True, False, False, False, False],\n       [False, False, False, False, False],\n       [ True, False, False, False, False],\n       [False, False, False,  True, False],\n       [False, False, False,  True, False],\n       [False, False,  True, False, False],\n       [False, False,  True, False, False],\n       [False, False, False, False, False],\n       [False, False, False, False, False],\n       [False, False, False, False, False],\n       [False, False, False, False, False],\n       [False, False, False,  True, False],\n       [False,  True, False, False, False],\n       [False, False, False,  True, False]])"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_encodes\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
