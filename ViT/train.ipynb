{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import timm\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import random_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "from tooth_crop_dataset import ToothCropClassDataset\n",
    "from utils.vit import train, test\n",
    "\n",
    "log_dir = Path('runs') / 'mobile_net_v2_th09'\n",
    "writer = SummaryWriter(log_dir=log_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# Data\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Preprocess\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    # (lambda image: padding_to_size(image, 224)),\n",
    "    transforms.Resize(size=(224, 224)),\n",
    "    transforms.Normalize(mean=0.5, std=0.5),\n",
    "])\n",
    "target_transform = transforms.Compose([\n",
    "    (lambda y: torch.Tensor(y)),\n",
    "])\n",
    "\n",
    "# Hyperparameter\n",
    "epoch_num = 240\n",
    "batch_size = 16\n",
    "num_workers = 0\n",
    "train_test_split = 0.8"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total data in 1041\n",
      "['R.R' 'caries' 'crown' 'endo' 'filling' 'post']\n",
      "tensor([ 23.,  53., 207., 216., 464., 134.])\n",
      "tensor([  5.,  16.,  55.,  61., 107.,  44.])\n"
     ]
    }
   ],
   "source": [
    "dataset = ToothCropClassDataset(root='../preprocess', transform=transform, target_transform=target_transform)\n",
    "\n",
    "dataset_size = len(dataset)\n",
    "train_size = int(train_test_split * dataset_size)\n",
    "test_size = dataset_size - train_size\n",
    "\n",
    "train_set, test_set = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size,\n",
    "                                           shuffle=True, num_workers=num_workers)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=num_workers)\n",
    "\n",
    "classes = dataset.mlb.classes_\n",
    "\n",
    "train_label_count = torch.zeros(len(classes))\n",
    "for x, y in train_loader:\n",
    "    train_label_count += y.sum(axis=0)\n",
    "\n",
    "test_label_count = torch.zeros(len(classes))\n",
    "for x, y in test_loader:\n",
    "    test_label_count += y.sum(axis=0)\n",
    "\n",
    "print(classes)\n",
    "print(train_label_count)\n",
    "print(test_label_count)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "model = timm.create_model('mobilenetv2_100', num_classes=6, pretrained=True)\n",
    "# model = timm.create_model('swin_base_patch4_window7_224', num_classes=4, pretrained=True)\n",
    "model.to(device)\n",
    "\n",
    "pos_weight = torch.tensor([1, 1, 1, 1, 1, 1]).to(device)\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "SGD_optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 240/240 [12:22<00:00,  3.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "Finished Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for t in tqdm(range(epoch_num)):\n",
    "    # print(f\"Epoch {t + 1}\\n-------------------------------\")\n",
    "    train(train_loader, model, criterion, SGD_optimizer, writer=writer, epoch=t, device=device)\n",
    "    test(test_loader, model, criterion, len(classes), device=device, writer=writer, epoch=t, classes=classes, threshold=0.9)\n",
    "\n",
    "writer.close()\n",
    "print(\"Done!\")\n",
    "\n",
    "print('Finished Training')\n",
    "# save your improved network\n",
    "torch.save(model.state_dict(), log_dir / 'trained-net.pt')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}